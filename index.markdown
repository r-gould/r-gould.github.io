---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: home
---

I am currently a 4th year mathematics student at the University of Cambridge, and an incoming EECS PhD student at UC Berkeley this fall. I am primarily interested in the development of reliable and safely deployable AI systems, with specific interests spanning:
* Alignment: Designing AI systems to be reliable and safe to deploy, with a focus on preventing *reward misspecification* (and subsequent *reward hacking*) as well as *robustness failures* due to *misgeneralization*.
* Evaluation: Evaluating whether a given AI system is aligned and behaves as intended, through *robust & scalable oversight* and *comprehensive behavioral evaluations*, with findings from evaluations (e.g. discovery of problematic behaviour) informing the alignment stage.
* Control: Mitigating the downstream effects of misalignment through robust inference-time detection and intervention pipelines during deployment.

Notes on these topics can be found [here](https://r-gould.github.io/2025/03/22/alignment-and-control.html). I am also interested in mathematical formalisms of intelligent behaviour, such as those based on variational inference (see [this post](https://r-gould.github.io/2024/09/23/variational-perception-action.html)).
