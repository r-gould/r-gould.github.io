---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: home
---

I am currently a 4th year mathematics student at the University of Cambridge studying theoretical physics, and an incoming CS PhD student at UC Berkeley this fall. I am broadly interested in understanding intelligent behavior from the perspective of both machine learning & neuroscience, and using related insights to design reliable AI systems.

In the context of LMs, I am mainly interested in:
* Alignment: Designing AI systems to be reliable and safe to deploy, with a focus on misspecification (outer alignment) and misgeneralization (inner alignment).
* Evaluation: Evaluating whether a given AI system is aligned and behaves as intended via scalable oversight and comprehensive behavioral evaluations, with findings from evaluations (e.g. discovery of unintended behaviour) informing the alignment stage.
* Control: Mitigating the downstream effects of misalignment through robust deployment-time detection and intervention.

Notes on these topics can be found [here](https://r-gould.github.io/2025/03/22/alignment-and-control.html). 

Beyond LMs, I am interested in mathematical formalisms of intelligent behavior based on the framework of variational inference (as in [this post](https://r-gould.github.io/2024/09/23/variational-perception-action.html)), and more generally, in deriving properties of intelligent behavior from simple mathematical principles (analogous to the [construction](https://r-gould.github.io/todo) of the Standard Model).
